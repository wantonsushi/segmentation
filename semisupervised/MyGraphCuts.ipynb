{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 \n",
    "# Part II: Semi-supervised Low-level Segmentation\n",
    "## (40% weight of the assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Your code should \"recreate\" representative results shown for graph cuts in Topic 9, but they do not have to be identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### Implement interactive seed-based segmentation using s/t graph cut.\n",
    "#### A basic seed-interactive GUI \"GraphCutsPresenter\" is available (implemented in \"asg1.py\"). The starter code below uses it. The presenter allows to add seeds (left and right mouse clicks for object and background seeds) and displays these seeds over the image. However, instead of proper graph cut segmentation the provided code displays some fixed binary mask (just as an example of a mask). This \"fixed\" mask should be replaced by the output of an interactive image segmentation method based on minimum s/t graph cut respecting the hard constraints marked by the user seeds. You can use an existing python library for computing minimum s/t cuts on arbitrary graphs (run \"$\\text{pip install PyMaxFlow}$\" in Anaconda Prompt, see <a href=\"http://pmneila.github.io/PyMaxflow/maxflow.html\">documentation</a>). You can use this library to build a weighted graph based on selected image and user-entered seeds.\n",
    "## Sub-problem 1.1 (70% weight of the problem)\n",
    "#### As a <font color=\"red\"> first milestone </font>, you should implement the most basic version of the graph cut algorithm for interactive image segmentation based on user seeds (see slides 9-12, topic 9B) that minimizes the following weak-supervision loss (see slides 13-18, topic 9B)  $$ -\\sum_{p\\in \\Omega_{\\mathcal L}} \\log S_p^{y_p} \\;\\;+\\;\\;\\lambda \\sum_{pq\\in N} w_{pq}\\,[S_p \\neq S_q] $$ combining the supervision loss, a.k.a. seed loss (hard constraints for user-defined labels), and basic pair-wise regularization loss with \"contrast-weights\" $w_{pq} = \\exp\\frac{-\\|I_p-I_q\\|^2}{\\sigma^2}$ for 4-connected grid neighborhood. Note that the scalar (hyper-parameter) $\\lambda$ controlling the regularization strength can be integrated into edge weights $\\tilde{w}_{pq} = \\lambda \\exp\\frac{-\\|I_p-I_q\\|^2}{\\sigma^2}$ (parameter $\\lambda$ is primarily needed for the second milestone below). Terminal \"t-links\" for seed-points should make sure that such graph nodes can not be severed from the corresponding terminals. You have to use \"large-enough\" finite cost t-links to enforce hard-constraints (user seeds) since \"infinity\" weight is not possible to implement. One can argue that $N\\cdot \\max \\{\\tilde{w}_{pq}\\}\\equiv N\\lambda$ (where N is the number of neighbors at each point) is sufficient.\n",
    "## Sub-problem 1.2 (30% weight of the problem)\n",
    "#### Once the first version of your interactive segmentation above is implemented and <u> tested</u>, your <font color=\"red\">second milestome </font> is to add color-based negative log-likelihoods (NLL), see slides 52 or 57 in topic 9B, into the total loss $$ -\\sum_p \\log Pr(I_p\\,|\\,\\theta_{S_p}) \\;\\;-\\;\\;\\sum_{p\\in \\Omega_{\\mathcal L}} \\log S_p^{y_p} \\;\\;+\\;\\;\\lambda\\sum_{pq\\in N} w_{pq}\\,[S_p \\neq S_q] $$ where two distinct color distributions $\\Pr(I|\\theta_1)$ and $\\Pr(I|\\theta_0)$ for two segments (object and backgound) should be estimated as GMMs from the corresponding seeds, as follows. As discussed in topic 9A (slides 60-61), GMM is a standard way to efficiently estimate arbitrary multi-modal probability density functions using relatively few parameters. Note that this assignment is not using GMMs to cluster seeds or any other pixels. We estimate one set of parameters $\\theta_1$ for the GMM probability denisty function $\\Pr(I|\\theta_1)$ for RGB colors at pixels with \"red\" seeds (treated as a sample of object features), and the second set of parameters $\\theta_0$ of the GMM probability density function $\\Pr(I|\\theta_0)$  for RGB colors at pixels with \"blue\" seeds (sample of background features). You do not need to implement EM algorithm (slide 67, topic 9A) for estimating $\\theta_1$ and $\\theta_0$, just use \"GaussianMixture\" function from the standard \"mixture\" library in \"sklearn\"; mixtures of six Gaussian modes ($K=6$) should suffice for each GMM density. Note that once you estimate two color distributions/densities (from seeds), then you can evaluate two likelihoods $\\Pr(I_p|\\theta_1)$ and $\\Pr(I_p|\\theta_0)$ at any pixel $p$, as required for the color log-likelihoods term in the total loss above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES/HINTS for both sub-problems\n",
    "#### NOTE 1: max-flow/min-cut libraries are typically more efficient when using integer edge weights in a relatively small range. You can use integer-weighted graph where edge weights are discretized/truncated values of your edge-weighting function.\n",
    "#### NOTE 2: Test different values of \"regularization parameter\" $\\lambda$ controlling relative weight of the regularization term versus the likelihoods terms.\n",
    "#### NOTE 3: Play with parameter $\\sigma$ for exponential n-link weighting function in $w_{pq}\\propto \\exp\\frac{-\\|I_p-I_q\\|^2}{\\sigma^2}$ using intensity differences/contrast between two pixels. Test different values of  $\\sigma$. Show 2-3 representative results (in different cells). Use markdown cell to discuss your observations, if any. If you can suggest some specific way of selecting some $\\sigma$ adaptively to each image, provide a brief technical motivation for it.\n",
    "#### NOTE 4: You can build either 4 or 8 nearest-neighbors (NN) grid.\n",
    "#### NOTE 5:  One numerical issue you may face are intensities/colors $I$ such that $Pr(I|\\theta_k)\\approx0$ where pixels with $I$ may still be present in segment $k$, but this intensity was not represented in the sample (seeds) used to estimate the distribution for segment $k$. This implies near-infinity log-likelihoods forbidding any pixel of color $I$ from segment $k$. Another issue could be that seeds for category $k$ may mistakenly include some pixels from the other category (e.g. if the user made errors when placing seeds). The core issue here is robustness of the log-likelihhood loss with respect to imperfect distributions/densities. There is a standard robustification trick (also used for log-likelihood losses in supervised network training to address labels with errors). The general idea is to modify (both segments) likelihoods as follows:  $$P'(I|\\theta_k) \\;=\\; \\gamma\\, P(I|\\theta_k) + \\frac{1-\\gamma}{\\|RGB\\|} $$ which can be derived as a mixture model for two distributions: $P$ and the uniform distribution over color space where $\\|RGB\\|$ is its cardinality. Essentially, robust modification of the log-likeliohood loss boils down to \n",
    "#### $$-log P(I|\\theta_k) \\;\\;\\;\\;\\;\\;\\rightarrow\\;\\;\\;\\;\\;\\;\\; -\\log \\left( P(I|\\theta_k) + \\epsilon \\right)$$ \n",
    "#### where $\\epsilon$ is an additional \"robustness\" parameter that bounds/truncates near-infinite log-likelighood penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE 6: (Creating n-links) Here is an illustration of one way of creating (undirected) n-links for the simplest 4-connected grid used in all examples of topic 9. First, you should compute two 2D arrays n_right and n_below (same shape as your image) where each element corresponding to pixel p is a weight wpq of n-link from this pixel to its neighbor q on the right or below (respectively). The weights should be computed according to the provided formula. You can use np.roll, np.exp, and other numpy functions to compute such arrays avoiding double-for-loops. Then, you can add the corresponding n-links to your graph as follows:\n",
    "\n",
    "g = maxflow.GraphFloat()\n",
    "\n",
    "nodeids = g.add_grid_nodes((num_rows, num_cols))\n",
    "\n",
    "structure_x = np.array([[0, 0, 0],\n",
    "                        [0, 0, 1],\n",
    "                        [0, 0, 0]])\n",
    "                        \n",
    "structure_y = np.array([[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 1, 0]])\n",
    "\n",
    "g.add_grid_edges(nodeids, weights=n_right, structure=structure_x, symmetric=True)\n",
    "\n",
    "g.add_grid_edges(nodeids, weights=n_below, structure=structure_y, symmetric=True)\n",
    "\n",
    "#### NOTE 7: (Creating t-links) Assume you already computed two 2D arrays t_sink and t_source (same shape as your image) where each element corresponding to pixel p is a weight of t-link from this pixel to the source or sink terminals (respectively). When computing such arrays, you should avoid double for-loops. Then, t-links can be created as below.\n",
    "\n",
    "g.add_grid_tedges( nodeids, t_source, t_sink )\n",
    "\n",
    "#### This function increments the weight of existing t-links, which are automatically created with each node (initialized to zero). You can call this function for the same nodes many times before or after the max-flow is computed. To update the solution after each modification of edge weights, you should call max-flow again. HINT:  if you need to change t-links to be equal to some particular \"new_weights\", you may need to create additional arrays storing current values of t-links and update t-links as follows:\n",
    "\n",
    "tlinks_source = np.zeros((num_rows,num_cols))\n",
    "\n",
    "tlinks_sink   = np.zeros((num_rows,num_cols))\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "g.add_grid_tedges( nodeids, new_weights_source - tlinks_source, new_weights_sink - tlinks_sink)\n",
    "\n",
    "tlinks_source = new_weights_source\n",
    "\n",
    "tlinks_sink   = new_weights_sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading standard library for GMM estimation\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# loading standard maxflow library (graph cuts)\n",
    "# Before importing maxflow first time, you must \"pip install PyMaxflow\" in Anaconda Prompt (see https://pypi.org/project/PyMaxflow/) \n",
    "import maxflow\n",
    "\n",
    "# loading custom module (requires file asg1.py in the same directory as the notebook file)\n",
    "from asg1_error_handling import Figure, GraphCutsPresenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGraphCuts:\n",
    "    bgr_value = 0\n",
    "    obj_value = 1\n",
    "    none_value = 2\n",
    "    \n",
    "    def __init__(self, img, sigma=0.5, lambd=0):\n",
    "        self.img = img\n",
    "        self.sigma = sigma                  # controls contrast sensitivity for n-link weights\n",
    "        self.lambd = lambd                  # boundary regularization parameter\n",
    "        \n",
    "        self.fig = Figure()\n",
    "        self.pres = GraphCutsPresenter(img, self)\n",
    "        self.pres.connect_figure(self.fig)\n",
    "\n",
    "        self.num_rows = img.shape[0]\n",
    "        self.num_cols = img.shape[1]\n",
    "\n",
    "    def run(self):\n",
    "        self.fig.show()\n",
    "\n",
    "    # fit GMMs to seeds\n",
    "    def fit_gmms(self, seed_mask):\n",
    "        # extract seed pixels for object vs background\n",
    "        pixels = self.img.reshape(-1, 3)\n",
    "        obj_pixels = pixels[seed_mask.flatten() == self.obj_value]\n",
    "        bgr_pixels = pixels[seed_mask.flatten() == self.bgr_value]\n",
    "        \n",
    "        # fit GMMs only if there are enough samples for object/background\n",
    "        self.obj_gmm = GaussianMixture(n_components=6, random_state=0) if len(obj_pixels) >= 2 else None\n",
    "        self.bgr_gmm = GaussianMixture(n_components=6, random_state=0) if len(bgr_pixels) >= 2 else None\n",
    "\n",
    "        if self.obj_gmm: self.obj_gmm.fit(obj_pixels)\n",
    "        if self.bgr_gmm: self.bgr_gmm.fit(bgr_pixels)\n",
    "    \n",
    "    # compute source and sink terminal links based on modified GMM log-likelihoods\n",
    "    def compute_t_links(self, seed_mask):\n",
    "        self.fit_gmms(seed_mask)                # fit GMMs\n",
    "        pixels = self.img.reshape(-1, 3)\n",
    "        \n",
    "        # default uniform log-likelihoods for unseen colors\n",
    "        default_log_likelihood = np.log(1.0 / 256**3)\n",
    "        obj_log_likelihood = np.full(pixels.shape[0], default_log_likelihood)\n",
    "        bgr_log_likelihood = np.full(pixels.shape[0], default_log_likelihood)\n",
    "\n",
    "        # update log-likelihoods using GMMs, if available\n",
    "        if self.obj_gmm: obj_log_likelihood = self.obj_gmm.score_samples(pixels)\n",
    "        if self.bgr_gmm: bgr_log_likelihood = self.bgr_gmm.score_samples(pixels)\n",
    "        \n",
    "        # Trick to avoid numerical instability and be robust in user error:\n",
    "        #   Combine likelihood with uniform distribution\n",
    "        #       P'(I|theta_k) = gamma * P(I|theta_k) + (1 - gamma) / |RGB|\n",
    "        #   Yielding the modified log-liklihood:\n",
    "        #       -log P'(I|theta_k) = -log(gamma * P(I|theta_k) + (1 - gamma) / |RGB|)\n",
    "\n",
    "        gamma = 0.75                           # weight given to GMM likelihood (lower = more uniform influence = more robust)\n",
    "        uniform_term = (1 - gamma) / (256**3)   \n",
    "\n",
    "        obj_cost = -np.log(gamma * np.exp(obj_log_likelihood) + uniform_term)\n",
    "        bgr_cost = -np.log(gamma * np.exp(bgr_log_likelihood) + uniform_term)\n",
    "\n",
    "        # reshape costs to image dimensions\n",
    "        obj_cost = obj_cost.reshape(self.num_rows, self.num_cols)\n",
    "        bgr_cost = bgr_cost.reshape(self.num_rows, self.num_cols)\n",
    "\n",
    "        # need to enforce hard constraints for seed pixels.\n",
    "        # assign high cost to ensure strict assignment (probably should be proportional to max cost)\n",
    "        seed_weight = 1e+8\n",
    "        t_source = np.where(seed_mask == self.obj_value, seed_weight, obj_cost)\n",
    "        t_sink = np.where(seed_mask == self.bgr_value, seed_weight, bgr_cost)\n",
    "\n",
    "        return t_source, t_sink\n",
    "    \n",
    "    # compute n-link weights based on intensity contrast\n",
    "    def compute_n_links(self):\n",
    "        # calculate the intensity differences for right and below neighbours\n",
    "        diff_right = np.roll(self.img, -1, axis=1) - self.img\n",
    "        diff_below = np.roll(self.img, -1, axis=0) - self.img\n",
    "        \n",
    "        # remove wrap-around differences\n",
    "        diff_right[:, -1, :] = 0\n",
    "        diff_below[-1, :, :] = 0\n",
    "        \n",
    "        # compute weights based on contrast and regularization parameter\n",
    "        n_right = self.lambd * np.exp(-np.linalg.norm(diff_right, axis=2)**2 / self.sigma**2)\n",
    "        n_below = self.lambd * np.exp(-np.linalg.norm(diff_below, axis=2)**2 / self.sigma**2)\n",
    "\n",
    "        return n_right, n_below\n",
    "\n",
    "    # perform graph cut and return segmentation labels\n",
    "    def compute_labels(self, seed_mask):\n",
    "        g = maxflow.Graph[float]()                                          # initialize graph\n",
    "        nodeids = g.add_grid_nodes((self.num_rows, self.num_cols))          # nodes for each pixel\n",
    "\n",
    "        n_right, n_below = self.compute_n_links()                           # compute n-links\n",
    "        \n",
    "        structure_right = np.array([[0, 0, 0],                              # define structures for right and below neighbors\n",
    "                                    [0, 0, 1], \n",
    "                                    [0, 0, 0]])\n",
    "        structure_below = np.array([[0, 0, 0],\n",
    "                                    [0, 0, 0],\n",
    "                                    [0, 1, 0]])                             # add n-links for neighbors in the graph\n",
    "        g.add_grid_edges(nodeids, n_right, structure=structure_right, symmetric=True)\n",
    "        g.add_grid_edges(nodeids, n_below, structure=structure_below, symmetric=True)\n",
    "\n",
    "        t_source, t_sink = self.compute_t_links(seed_mask)                  # compute and add t-links to the graph\n",
    "        g.add_grid_tedges(nodeids, t_source, t_sink)\n",
    "\n",
    "        g.maxflow()                                                         # get segmentation\n",
    "        segments = g.get_grid_segments(nodeids)\n",
    "\n",
    "        label_mask = np.where(segments, self.obj_value, self.bgr_value)     # make mask \n",
    "\n",
    "        return label_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about the basic graph cut interface:\n",
    "1. To provide the regional hard constraints (seeds) for object and background segments use left and right mouse clicks (mouse dragging works somewhat too). Use mouse wheel to change the brush size.\n",
    "2. The seed mask is built by the \"GraphCutsPresenter\". Each mouse release activates \"on_mouse_up\" function of the presenter, which asks the linked MyGraphCuts object to \"compute_labels\" for all pixels\n",
    "based on the provided seed mask.\n",
    "3. You should use \"PyMaxflow\" library (already imported into this notebook if you ran the second cell) to build a weighted graph and to compute a minimum s/t cut defining all pixel labels from the seeds as explain in topic 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bunny Reference Image\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/bunny.bmp\" height=\"250\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = plt.imread('images/bunny.bmp')\n",
    "\n",
    "#app = MyGraphCuts(img1, sigma=0.5, lambd=5.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/bunny1a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/bunny1b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img1, sigma=5.0, lambd=5.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/bunny2a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/bunny2b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img1, sigma=50.0, lambd=5.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/bunny3a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/bunny3b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img1, sigma=500.0, lambd=5.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/bunny4a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/bunny4b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "\n",
    "#### Discussion on segmentation using different $\\sigma$:\n",
    "\n",
    "At low values of $\\sigma$, segmentation boundaries are highly sensitive to contrasting edges. Boundaries are very sharp and defined but small intensity variations from noise and texture can be seen incorrectly segmented into smaller parts.\n",
    "\n",
    "As $\\sigma$ increases, intensity differences are downweighted less significantly. The segmentation becomes smoother, but boundaries are blurred are the size of segments become larger.\n",
    "\n",
    "To select $\\sigma$ adaptively for each image, we could consider the intensity distribution and contrast within the image. For example, for each pixel \n",
    "$p$, compute the mean or median intensity difference with its neighbors. We can then use these local contrast values to estimate an overall scale of intensity variation in the image.\n",
    "\n",
    "In conclusion, the parameter $\\sigma$ influences the segmentation outcome by controlling the contrast sensitivity of n-links. An adaptive strategy, based on local contrast statistics, may provide a robust method to balance edge preservation and smoothness across diverse images.\n",
    "\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Show how your interactive segmenter works on more challanging images where there is some overlap between the color-models in the object and background (as in the \"lama\" image). Compare the results for $\\lambda=0$ (no regularization) and for some $\\lambda>0$. For convenience, you might want to include $\\lambda$ in the list of parameters for the function \"MyGraphcuts\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lama Reference Image\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/lama.jpg\" height=\"250\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = plt.imread('images/lama.jpg')\n",
    "\n",
    "#app = MyGraphCuts(img2, sigma=50.0, lambd=0.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/lama1a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/lama1b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img2, sigma=50.0, lambd=10.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/lama2a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/lama2b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img2, sigma=50.0, lambd=100.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/lama3a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/lama3b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = MyGraphCuts(img2, sigma=50.0, lambd=1000.0)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/Part2Plots/lama4a.png\" height=\"300\"/>\n",
    "    <img src=\"images/Part2Plots/lama4b.png\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "\n",
    "#### Discussion on segmentation using different $\\lambda$:\n",
    "\n",
    "With $\\lambda = 0$ (ie. no regularization), segmentation depends solely on the color-based likelihoods, meaning the labels assigned to pixels are determined entirely by the similarity of pixel colors to the GMMs fitted to the seed regions. In the lama image, areas with similar colors in the fur and background were misclassified due to similarity in the color, and a reliance on that data alone.\n",
    "\n",
    "As $\\lambda$ increases, segmentation is encouraged to maintain spatial coherence. Segmentation boundaries become smoother and more regularized, overlapping regions are better resolved, and there is a significant reduction in noise. However, it can lead to oversmoothing and loss to finer details. \n",
    "\n",
    "______________________________"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
